{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd7037f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-ad005be2d5db>, line 130)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-ad005be2d5db>\"\u001b[1;36m, line \u001b[1;32m130\u001b[0m\n\u001b[1;33m    test_flagrun=False,\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# SPDX-FileCopyrightText: Copyright (c) 2022 Guillaume Bellegarda. All rights reserved.\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "# \n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "# 1. Redistributions of source code must retain the above copyright notice, this\n",
    "# list of conditions and the following disclaimer.\n",
    "#\n",
    "# 2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "# this list of conditions and the following disclaimer in the documentation\n",
    "# and/or other materials provided with the distribution.\n",
    "#\n",
    "# 3. Neither the name of the copyright holder nor the names of its\n",
    "# contributors may be used to endorse or promote products derived from\n",
    "# this software without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
    "# FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "# DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
    "# SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
    "# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
    "# OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
    "# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "#\n",
    "# Copyright (c) 2022 EPFL, Guillaume Bellegarda\n",
    "\n",
    "\"\"\"This file implements the gym environment for a quadruped. \"\"\"\n",
    "import os, inspect\n",
    "# so we can import files\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "os.sys.path.insert(0, currentdir)\n",
    "\n",
    "import time, datetime\n",
    "import numpy as np\n",
    "# gym\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "# pybullet\n",
    "import pybullet\n",
    "import pybullet_utils.bullet_client as bc\n",
    "import pybullet_data\n",
    "import random\n",
    "random.seed(10)\n",
    "# quadruped and configs\n",
    "import quadruped\n",
    "import configs_a1 as robot_config\n",
    "from hopf_network import HopfNetwork\n",
    "\n",
    "# few helpers \n",
    "def unit_vector(vector):\n",
    "\t\"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "\treturn vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "\t\"\"\" Returns the angle in radians between vectors 'v1' and 'v2' \"\"\"\n",
    "\tv1_u = unit_vector(v1)\n",
    "\tv2_u = unit_vector(v2)\n",
    "\treturn np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "def rotation_matrix(theta):\n",
    "\treturn np.array([ [np.cos(theta), -np.sin(theta) ], [np.sin(theta), np.cos(theta)] ])\n",
    "\n",
    "\n",
    "ACTION_EPS = 0.01\n",
    "OBSERVATION_EPS = 0.01\n",
    "VIDEO_LOG_DIRECTORY = 'videos/' + datetime.datetime.now().strftime(\"vid-%Y-%m-%d-%H-%M-%S-%f\")\n",
    "\n",
    "# Implemented observation spaces for deep reinforcement learning: \n",
    "#   \"DEFAULT\":    motor angles and velocities, body orientation\n",
    "#   \"LR_COURSE_OBS\":  [TODO: what should you include? what is reasonable to measure on the real system? CPG states?] \n",
    "\n",
    "# Tasks to be learned with reinforcement learning\n",
    "#     - \"FWD_LOCOMOTION\"\n",
    "#         reward forward progress only\n",
    "#     - \"FLAGRUN\"\n",
    "#         move to goal, once reached, a new goal is randomly selected.\n",
    "#     - \"LR_COURSE_TASK\" \n",
    "#         [TODO: what should you train for?]\n",
    "#         Ideally we want to command A1 to run in any direction while expending minimal energy\n",
    "#         How will you construct your reward function? \n",
    "\n",
    "# Motor control modes:\n",
    "#   - \"TORQUE\": \n",
    "#         supply raw torques to each motor (12)\n",
    "#   - \"PD\": \n",
    "#         supply desired joint positions to each motor (12)\n",
    "#         torques are computed based on the joint position/velocity error\n",
    "#   - \"CARTESIAN_PD\": \n",
    "#         supply desired foot positions for each leg (12)\n",
    "#         torques are computed based on the foot position/velocity error\n",
    "#   - \"CPG\": \n",
    "#         supply desired CPG state modulations (8), mapped to foot positions\n",
    "#         torques are computed based on inverse kinematics + joint PD (or you can add Cartesian PD)\n",
    "\n",
    "\n",
    "EPISODE_LENGTH = 10   # how long before we reset the environment (max episode length for RL)\n",
    "MAX_FWD_VELOCITY = 1  # to avoid exploiting simulator dynamics, cap max reward for body velocity \n",
    "\n",
    "# CPG quantities\n",
    "MU_LOW = 1\n",
    "MU_UPP = 2\n",
    "\n",
    "\n",
    "class QuadrupedGymEnv(gym.Env):\n",
    "  \"\"\"The gym environment for a quadruped {Unitree A1}.\n",
    "\n",
    "  It simulates the locomotion of a quadrupedal robot. \n",
    "  The state space, action space, and reward functions can be chosen with:\n",
    "  observation_space_mode, motor_control_mode, task_env.\n",
    "  \"\"\"\n",
    "  def __init__(\n",
    "      self,\n",
    "      robot_config=robot_config,\n",
    "      isRLGymInterface=True,\n",
    "      time_step=0.001,\n",
    "      action_repeat=10,  \n",
    "      motor_control_mode=\"PD\",\n",
    "      task_env=\"LR_COURSE_TASK\",\n",
    "      observation_space_mode=\"DEFAULT\",\n",
    "      on_rack=False,\n",
    "      render=False,\n",
    "      record_video=False,\n",
    "      add_noise=True,\n",
    "      terrain= \"STAIRS\" #None,\n",
    "      test_flagrun=False, \n",
    "      **kwargs): # any extra arguments from legacy\n",
    "    \"\"\"Initialize the quadruped gym environment.\n",
    "\n",
    "    Args:\n",
    "      robot_config: The robot config file, contains A1 parameters.\n",
    "      isRLGymInterface: If the gym environment is being run as RL or not. Affects\n",
    "        if the actions should be scaled.\n",
    "      time_step: Simulation time step.\n",
    "      action_repeat: The number of simulation steps where the same actions are applied.\n",
    "      motor_control_mode: Whether to use torque control, PD, control, CPG, etc.\n",
    "      task_env: Task trying to learn (fwd locomotion, standup, etc.)\n",
    "      observation_space_mode: what should be in here? Check available functions in quadruped.py\n",
    "        also consider CPG states (amplitudes/phases)\n",
    "      on_rack: Whether to place the quadruped on rack. This is only used to debug\n",
    "        the walking gait. In this mode, the quadruped's base is hanged midair so\n",
    "        that its walking gait is clearer to visualize.\n",
    "      render: Whether to render the simulation.\n",
    "      record_video: Whether to record a video of each trial.\n",
    "      add_noise: vary coefficient of friction\n",
    "      terrain: string indicating what kind of terrain (\"STAIRS\", \"SLOPES\", \"GAPS\", \"RANDOM\")\n",
    "      test_flagrun: follow certain goals in order, fixed coefficient of friction \n",
    "    \"\"\"\n",
    "    self._robot_config = robot_config\n",
    "    self._isRLGymInterface = isRLGymInterface\n",
    "    self._time_step = time_step\n",
    "    self._action_repeat = action_repeat\n",
    "    self._motor_control_mode = motor_control_mode\n",
    "    self._TASK_ENV = task_env\n",
    "    self._observation_space_mode = observation_space_mode\n",
    "    self._hard_reset = True # must fully reset simulation at init\n",
    "    self._on_rack = on_rack\n",
    "    self._is_render = render\n",
    "    self._is_record_video = record_video\n",
    "    self._add_noise = add_noise\n",
    "    self._using_test_env = test_env\n",
    "    self._test_flagrun = test_flagrun\n",
    "    self.goal_id = None\n",
    "    self._terrain = terrain\n",
    "    if self._add_noise:\n",
    "      self._observation_noise_stdev = 0.01 #\n",
    "    else:\n",
    "      self._observation_noise_stdev = 0.0\n",
    "\n",
    "    # other bookkeeping \n",
    "    self._num_bullet_solver_iterations = int(300 / action_repeat) \n",
    "    self._env_step_counter = 0\n",
    "    self._sim_step_counter = 0\n",
    "    self._last_base_position = [0, 0, 0]\n",
    "    self._last_frame_time = 0.0 # for rendering \n",
    "    self._MAX_EP_LEN = EPISODE_LENGTH # max sim time in seconds, arbitrary\n",
    "    self._action_bound = 1.0\n",
    "\n",
    "    # if using CPG\n",
    "    self.setupCPG()\n",
    "\n",
    "    self.setupActionSpace()\n",
    "    self.setupObservationSpace()\n",
    "    if self._is_render:\n",
    "      self._pybullet_client = bc.BulletClient(connection_mode=pybullet.GUI)\n",
    "    else:\n",
    "      self._pybullet_client = bc.BulletClient()\n",
    "    self._configure_visualizer()\n",
    "\n",
    "    self.videoLogID = None\n",
    "    self.seed()\n",
    "    self.reset()\n",
    " \n",
    "  def setupCPG(self):\n",
    "    self._cpg = HopfNetwork(use_RL=True)\n",
    "\n",
    "  ######################################################################################\n",
    "  # RL Observation and Action spaces \n",
    "  ######################################################################################\n",
    "  def setupObservationSpace(self):\n",
    "    \"\"\"Set up observation space for RL. \"\"\"\n",
    "    if self._observation_space_mode == \"DEFAULT\":\n",
    "      observation_high = (np.concatenate((self._robot_config.UPPER_ANGLE_JOINT,\n",
    "                                         self._robot_config.VELOCITY_LIMITS,\n",
    "                                         np.array([1.0]*4))) +  OBSERVATION_EPS)\n",
    "      observation_low = (np.concatenate((self._robot_config.LOWER_ANGLE_JOINT,\n",
    "                                         -self._robot_config.VELOCITY_LIMITS,\n",
    "                                         np.array([-1.0]*4))) -  OBSERVATION_EPS)\n",
    "    elif self._observation_space_mode == \"LR_COURSE_OBS\":\n",
    "      # [TODO] Set observation upper and lower ranges. What are reasonable limits? \n",
    "      # Note 50 is arbitrary below, you may have more or less\n",
    "      # if using CPG-RL, remember to include limits on these\n",
    "      observation_high = (np.zeros(50) + OBSERVATION_EPS)\n",
    "      observation_low = (np.zeros(50) -  OBSERVATION_EPS)\n",
    "    else:\n",
    "      raise ValueError(\"observation space not defined or not intended\")\n",
    "\n",
    "    self.observation_space = spaces.Box(observation_low, observation_high, dtype=np.float32)\n",
    "\n",
    "  def setupActionSpace(self):\n",
    "    \"\"\" Set up action space for RL. \"\"\"\n",
    "    if self._motor_control_mode in [\"PD\",\"TORQUE\", \"CARTESIAN_PD\"]:\n",
    "      action_dim = 12\n",
    "    elif self._motor_control_mode in [\"CPG\"]:\n",
    "      action_dim = 8\n",
    "    else:\n",
    "      raise ValueError(\"motor control mode \" + self._motor_control_mode + \" not implemented yet.\")\n",
    "    action_high = np.array([1] * action_dim)\n",
    "    self.action_space = spaces.Box(-action_high, action_high, dtype=np.float32)\n",
    "    self._action_dim = action_dim\n",
    "\n",
    "\n",
    "  def _get_observation(self):\n",
    "    \"\"\"Get observation, depending on obs space selected. \"\"\"\n",
    "    if self._observation_space_mode == \"DEFAULT\":\n",
    "      self._observation = np.concatenate((self.robot.GetMotorAngles(), \n",
    "                                          self.robot.GetMotorVelocities(),\n",
    "                                          self.robot.GetBaseOrientation() ))\n",
    "    elif self._observation_space_mode == \"LR_COURSE_OBS\":\n",
    "      # [TODO] Get observation from robot. What are reasonable measurements we could get on hardware?\n",
    "      # if using the CPG, you can include states with self._cpg.get_r(), for example\n",
    "      # 50 is arbitrary\n",
    "      self._observation = np.zeros(50)\n",
    "\n",
    "    else:\n",
    "      raise ValueError(\"observation space not defined or not intended\")\n",
    "\n",
    "    self._add_obs_noise = (np.random.normal(scale=self._observation_noise_stdev, size=self._observation.shape) *\n",
    "          self.observation_space.high)\n",
    "    return self._observation\n",
    "\n",
    "  def _noisy_observation(self):\n",
    "    self._get_observation()\n",
    "    observation = np.array(self._observation)\n",
    "    if self._observation_noise_stdev > 0:\n",
    "      observation += self._add_obs_noise\n",
    "    return observation\n",
    "\n",
    "  ######################################################################################\n",
    "  # Termination and reward\n",
    "  ######################################################################################\n",
    "  def is_fallen(self,dot_prod_min=0.85):\n",
    "    \"\"\"Decide whether the quadruped has fallen.\n",
    "\n",
    "    If the up directions between the base and the world is larger (the dot\n",
    "    product is smaller than 0.85) or the base is very low on the ground\n",
    "    (the height is smaller than 0.13 meter), the quadruped is considered fallen.\n",
    "\n",
    "    Returns:\n",
    "      Boolean value that indicates whether the quadruped has fallen.\n",
    "    \"\"\"\n",
    "    base_rpy = self.robot.GetBaseOrientationRollPitchYaw()\n",
    "    orientation = self.robot.GetBaseOrientation()\n",
    "    rot_mat = self._pybullet_client.getMatrixFromQuaternion(orientation)\n",
    "    local_up = rot_mat[6:]\n",
    "    pos = self.robot.GetBasePosition()\n",
    "    return (np.dot(np.asarray([0, 0, 1]), np.asarray(local_up)) < dot_prod_min or pos[2] < self._robot_config.IS_FALLEN_HEIGHT)\n",
    "\n",
    "  def _termination(self):\n",
    "    \"\"\"Decide whether we should stop the episode and reset the environment. \"\"\"\n",
    "    return self.is_fallen() \n",
    "\n",
    "  def _reward_fwd_locomotion(self, des_vel_x=None):\n",
    "    \"\"\"Learn forward locomotion\"\"\"\n",
    "    vel_tracking_reward = 0.1 * np.clip(self.robot.GetBaseLinearVelocity()[0], 0.2, 1.0)\n",
    "    # If you want to track a desired velocity \n",
    "    # vel_tracking_reward = 0.05 * np.exp( -1/ 0.25 *  (self.robot.GetBaseLinearVelocity()[0] - des_vel_x)**2 )\n",
    "    # minimize yaw (go straight)\n",
    "    yaw_reward = -0.2 * np.abs(self.robot.GetBaseOrientationRollPitchYaw()[2]) \n",
    "    # don't drift laterally \n",
    "    drift_reward = -0.01 * abs(self.robot.GetBasePosition()[1]) \n",
    "    # minimize energy \n",
    "    energy_reward = 0 \n",
    "    for tau,vel in zip(self._dt_motor_torques,self._dt_motor_velocities):\n",
    "      energy_reward += np.abs(np.dot(tau,vel)) * self._time_step\n",
    "\n",
    "    reward = vel_tracking_reward \\\n",
    "            + yaw_reward \\\n",
    "            + drift_reward \\\n",
    "            - 0.01 * energy_reward \\\n",
    "            - 0.1 * np.linalg.norm(self.robot.GetBaseOrientation() - np.array([0,0,0,1]))\n",
    "\n",
    "    return max(reward,0) # keep rewards positive\n",
    "\n",
    "  def get_distance_and_angle_to_goal(self):\n",
    "    \"\"\" Helper to return distance and angle to current goal location. \"\"\"\n",
    "    # current object location\n",
    "    base_pos = self.robot.GetBasePosition()\n",
    "    yaw = self.robot.GetBaseOrientationRollPitchYaw()[2]\n",
    "    goal_vec = self._goal_location\n",
    "    dist_to_goal = np.linalg.norm(base_pos[0:2]-goal_vec)\n",
    "\n",
    "    # angle to goal (from current heading)\n",
    "    body_dir_vec = np.matmul( rotation_matrix(yaw), np.array([[1],[0]]) )\n",
    "    body_goal_vec = goal_vec - base_pos[0:2]\n",
    "    body_dir_vec = body_dir_vec.reshape(2,)\n",
    "    body_goal_vec = body_goal_vec.reshape(2,)\n",
    "\n",
    "    Vn = unit_vector( np.array([0,0,1]) )\n",
    "    c = np.cross( np.hstack([body_dir_vec,0]), np.hstack([body_goal_vec,0])  )\n",
    "    angle = angle_between(body_dir_vec, body_goal_vec)\n",
    "    angle = angle * np.sign( np.dot( Vn , c ) )\n",
    "\n",
    "    return dist_to_goal, angle\n",
    "  \n",
    "  def _reward_flag_run(self):\n",
    "    \"\"\" Learn to move towards goal location. \"\"\"\n",
    "    curr_dist_to_goal, angle = self.get_distance_and_angle_to_goal()\n",
    "\n",
    "    # minimize distance to goal (we want to move towards the goal)\n",
    "    dist_reward = 10 * ( self._prev_pos_to_goal - curr_dist_to_goal)\n",
    "    # minimize yaw deviation to goal (necessary?)\n",
    "    yaw_reward = 0 # -0.01 * np.abs(angle) \n",
    "\n",
    "    # minimize energy \n",
    "    energy_reward = 0 \n",
    "    for tau,vel in zip(self._dt_motor_torques,self._dt_motor_velocities):\n",
    "      energy_reward += np.abs(np.dot(tau,vel)) * self._time_step\n",
    "\n",
    "    reward = dist_reward \\\n",
    "            + yaw_reward \\\n",
    "            - 0.001 * energy_reward \n",
    "    \n",
    "    return max(reward,0) # keep rewards positive\n",
    "    \n",
    "  def _reward_lr_course(self):\n",
    "    \"\"\" Implement your reward function here. How will you improve upon the above? \"\"\"\n",
    "    # [TODO] add your reward function. \n",
    "    yaw_reward = -0.2 * np.abs(self.robot.GetBaseOrientationRollPitchYaw()[2])\n",
    "    drift_reward = -0.01 * abs(self.robot.GetBasePosition()[1])\n",
    "    \n",
    "    energy_reward = 0 \n",
    "    for tau,vel in zip(self._dt_motor_torques,self._dt_motor_velocities):\n",
    "      energy_reward += np.abs(np.dot(tau,vel)) * self._time_step\n",
    "    \n",
    "    velocity_reward = 0.1 * self.robot.GetBaseLinearVelocity()[0]\n",
    "    height_reward = 0.1 * self.robot.GetBasePosition()[2]\n",
    "    \n",
    "    reward = yaw_reward \\\n",
    "            + drift_reward \\\n",
    "            - 0.001 * energy_reward \\\n",
    "            + velocity_reward \\\n",
    "            + height_reward\n",
    "    \n",
    "    return max(reward,0) # keep rewards positive\n",
    "\n",
    "  def _reward(self):\n",
    "    \"\"\" Get reward depending on task\"\"\"\n",
    "    if self._TASK_ENV == \"FWD_LOCOMOTION\":\n",
    "      return self._reward_fwd_locomotion()\n",
    "    elif self._TASK_ENV == \"LR_COURSE_TASK\":\n",
    "      return self._reward_lr_course()\n",
    "    elif self._TASK_ENV == \"FLAGRUN\":\n",
    "      return self._reward_flag_run()\n",
    "    else:\n",
    "      raise ValueError(\"This task mode not implemented yet.\")\n",
    "\n",
    "  ######################################################################################\n",
    "  # Step simulation, map policy network actions to joint commands, etc. \n",
    "  ######################################################################################\n",
    "  def _transform_action_to_motor_command(self, action):\n",
    "    \"\"\" Map actions from RL (i.e. in [-1,1]) to joint commands based on motor_control_mode. \"\"\"\n",
    "    # clip actions to action bounds\n",
    "    action = np.clip(action, -self._action_bound - ACTION_EPS,self._action_bound + ACTION_EPS)\n",
    "    if self._motor_control_mode == \"PD\":\n",
    "      action = self._scale_helper(action, self._robot_config.LOWER_ANGLE_JOINT, self._robot_config.UPPER_ANGLE_JOINT)\n",
    "      action = np.clip(action, self._robot_config.LOWER_ANGLE_JOINT, self._robot_config.UPPER_ANGLE_JOINT)\n",
    "    elif self._motor_control_mode == \"CARTESIAN_PD\":\n",
    "      action = self.ScaleActionToCartesianPos(action)\n",
    "    elif self._motor_control_mode == \"CPG\":\n",
    "      action = self.ScaleActionToCPGStateModulations(action)\n",
    "    else:\n",
    "      raise ValueError(\"RL motor control mode\" + self._motor_control_mode + \"not implemented yet.\")\n",
    "    return action\n",
    "\n",
    "  def _scale_helper(self, action, lower_lim, upper_lim):\n",
    "    \"\"\"Helper to linearly scale from [-1,1] to lower/upper limits. \"\"\"\n",
    "    new_a = lower_lim + 0.5 * (action + 1) * (upper_lim - lower_lim)\n",
    "    return np.clip(new_a, lower_lim, upper_lim)\n",
    "\n",
    "  def ScaleActionToCartesianPos(self,actions):\n",
    "    \"\"\"Scale RL action to Cartesian PD ranges. \n",
    "    Edit ranges, limits etc., but make sure to use Cartesian PD to compute the torques. \n",
    "    \"\"\"\n",
    "    # clip RL actions to be between -1 and 1 (standard RL technique)\n",
    "    u = np.clip(actions,-1,1)\n",
    "    # scale to corresponding desired foot positions (i.e. ranges in x,y,z we allow the agent to choose foot positions)\n",
    "    # [TODO: edit (do you think these should these be increased? How limiting is this?)]\n",
    "    scale_array = np.array([0.1, 0.05, 0.08]*4)\n",
    "    # add to nominal foot position in leg frame (what are the final ranges?)\n",
    "    des_foot_pos = self._robot_config.NOMINAL_FOOT_POS_LEG_FRAME + scale_array*u\n",
    "\n",
    "    # get Cartesian kp and kd gains (can be modified)\n",
    "    kpCartesian = self._robot_config.kpCartesian\n",
    "    kdCartesian = self._robot_config.kdCartesian\n",
    "    # get current motor velocities\n",
    "    qd = self.robot.GetMotorVelocities()\n",
    "\n",
    "    action = np.zeros(12)\n",
    "    for i in range(4):\n",
    "      # get Jacobian and foot position in leg frame for leg i (see ComputeJacobianAndPosition() in quadruped.py)\n",
    "      # [TODO]\n",
    "      J, pos = self.robot.ComputeJacobianAndPosition(i)\n",
    "      # desired foot position i (from RL above)\n",
    "      Pd = np.zeros(3) # [TODO]\n",
    "      Pd = des_foot_pos[3*i:3*i+3]\n",
    "      # desired foot velocity i\n",
    "      vd = np.zeros(3)\n",
    "      # foot velocity in leg frame i (Equation 2)\n",
    "      # [TODO]\n",
    "      v = J @ qd[3*i:3*i+3]\n",
    "\n",
    "      # calculate torques with Cartesian PD (Equation 5) [Make sure you are using matrix multiplications]\n",
    "      tau = np.zeros(3) # [TODO]\n",
    "      tau = J.T @ (kpCartesian @ (Pd - pos) + kdCartesian @ (vd - v))\n",
    "\n",
    "      action[3*i:3*i+3] = tau\n",
    "\n",
    "    return action\n",
    "\n",
    "  def ScaleActionToCPGStateModulations(self,actions):\n",
    "    \"\"\"Scale RL action to CPG modulation parameters.\"\"\"\n",
    "    # clip RL actions to be between -1 and 1 (standard RL technique)\n",
    "    u = np.clip(actions,-1,1)\n",
    "\n",
    "    # scale omega to ranges, and set in CPG (range is an example)\n",
    "    omega = self._scale_helper( u[0:4], 5, 4.5*2*np.pi)\n",
    "    self._cpg.set_omega_rl(omega)\n",
    "\n",
    "    # scale mu to ranges, and set in CPG (squared since we converge to the sqrt in the CPG amplitude)\n",
    "    mus = self._scale_helper( u[4:8], MU_LOW*2, MU_UPP*2)\n",
    "    self._cpg.set_mu_rl(mus)\n",
    "\n",
    "    # integrate CPG, get mapping to foot positions\n",
    "    xs,zs = self._cpg.update()\n",
    "\n",
    "    # IK parameters\n",
    "    foot_y = self._robot_config.HIP_LINK_LENGTH\n",
    "    sideSign = np.array([-1, 1, -1, 1]) # get correct hip sign (body right is negative)\n",
    "    # get motor kp and kd gains (can be modified)\n",
    "    kp = self._robot_config.MOTOR_KP # careful of size!\n",
    "    kd = self._robot_config.MOTOR_KD\n",
    "    # get current motor velocities\n",
    "    q = self.robot.GetMotorAngles()\n",
    "    dq = self.robot.GetMotorVelocities()\n",
    "\n",
    "    action = np.zeros(12)\n",
    "    # loop through each leg\n",
    "    for i in range(4):\n",
    "      # get desired foot i pos (xi, yi, zi)\n",
    "      x = xs[i]\n",
    "      y = sideSign[i] * foot_y # careful of sign\n",
    "      z = zs[i]\n",
    "\n",
    "      # call inverse kinematics to get corresponding joint angles\n",
    "      q_des = np.zeros(3) # [TODO]\n",
    "      q_des = self.robot.ComputeInverseKinematics(i, np.array([x, y, z]))\n",
    "      # Add joint PD contribution to tau\n",
    "      tau = np.zeros(3) # [TODO]\n",
    "      leg_dq = np.zeros(3)  # Desired joint velocity\n",
    "\n",
    "      leg_xyz_desired = np.array([xs[i], sideSign[i] * foot_y, zs[i]])\n",
    "      leg_q = self.robot.ComputeInverseKinematics(i, leg_xyz_desired)\n",
    "      joint_position_error = leg_q - q[3 * i:3 * i + 3]\n",
    "      joint_velocity_error = leg_dq - dq[3 * i:3 * i + 3]\n",
    "\n",
    "      tau = kp[3*i:3*i+3] * joint_position_error + kd[3*i:3*i+3] * joint_velocity_error\n",
    "\n",
    "      # add Cartesian PD contribution (as you wish)\n",
    "      # tau +=\n",
    "\n",
    "      action[3*i:3*i+3] = tau\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "  def step(self, action):\n",
    "    \"\"\" Step forward the simulation, given the action. \"\"\"\n",
    "    curr_act = action.copy()\n",
    "    # save motor torques and velocities to compute power in reward function\n",
    "    self._dt_motor_torques = []\n",
    "    self._dt_motor_velocities = []\n",
    "    if \"FLAGRUN\" in self._TASK_ENV:\n",
    "      self._prev_pos_to_goal, _ = self.get_distance_and_angle_to_goal()\n",
    "    \n",
    "    for _ in range(self._action_repeat):\n",
    "      if self._isRLGymInterface: \n",
    "        proc_action = self._transform_action_to_motor_command(curr_act)\n",
    "      else:\n",
    "        proc_action = curr_act \n",
    "      self.robot.ApplyAction(proc_action)\n",
    "      self._pybullet_client.stepSimulation()\n",
    "      self._sim_step_counter += 1\n",
    "      self._dt_motor_torques.append(self.robot.GetMotorTorques())\n",
    "      self._dt_motor_velocities.append(self.robot.GetMotorVelocities())\n",
    "\n",
    "      if self._is_render:\n",
    "        self._render_step_helper()\n",
    "\n",
    "    self._last_action = curr_act\n",
    "    self._env_step_counter += 1\n",
    "    reward = self._reward()\n",
    "    done = False\n",
    "    if self._termination() or (self.get_sim_time() > self._MAX_EP_LEN and not self._test_flagrun ):\n",
    "      done = True\n",
    "\n",
    "    if \"FLAGRUN\" in self._TASK_ENV:\n",
    "      dist_to_goal, _ = self.get_distance_and_angle_to_goal()\n",
    "      if dist_to_goal < 0.5:\n",
    "        self._reset_goal()\n",
    "\n",
    "    return np.array(self._noisy_observation()), reward, done, {'base_pos': self.robot.GetBasePosition()} \n",
    "\n",
    "  ######################################################################################\n",
    "  # Reset\n",
    "  ######################################################################################\n",
    "  def reset(self):\n",
    "    \"\"\" Set up simulation environment. \"\"\"\n",
    "    mu_min = 0.5\n",
    "    if self._hard_reset:\n",
    "      # set up pybullet simulation\n",
    "      self._pybullet_client.resetSimulation()\n",
    "      self._pybullet_client.setPhysicsEngineParameter(\n",
    "          numSolverIterations=int(self._num_bullet_solver_iterations))\n",
    "      self._pybullet_client.setTimeStep(self._time_step)\n",
    "      self.plane = self._pybullet_client.loadURDF(pybullet_data.getDataPath()+\"/plane.urdf\", \n",
    "                                                  basePosition=[80,0,0]) # to extend available running space (shift)\n",
    "      self._pybullet_client.changeVisualShape(self.plane, -1, rgbaColor=[1, 1, 1, 0.9])\n",
    "      self._pybullet_client.configureDebugVisualizer(\n",
    "          self._pybullet_client.COV_ENABLE_PLANAR_REFLECTION, 0)\n",
    "      self._pybullet_client.setGravity(0, 0, -9.8)\n",
    "      if self._terrain == \"GAPS\":\n",
    "        self._robot_config.INIT_POSITION[2] = 1.305\n",
    "        self._robot_config.IS_FALLEN_HEIGHT = 1.18\n",
    "      self.robot = (quadruped.Quadruped(pybullet_client=self._pybullet_client,\n",
    "                                         robot_config=self._robot_config,\n",
    "                                         motor_control_mode=self._motor_control_mode,\n",
    "                                         on_rack=self._on_rack,\n",
    "                                         render=self._is_render))\n",
    "      self._ground_mu_k = 1\n",
    "      if self._add_noise:\n",
    "        ground_mu_k = mu_min+(1-mu_min)*np.random.random()\n",
    "        self._ground_mu_k = ground_mu_k\n",
    "        self._pybullet_client.changeDynamics(self.plane, -1, lateralFriction=ground_mu_k)\n",
    "        self._add_base_mass_offset()\n",
    "        if self._is_render:\n",
    "          print('ground friction coefficient is', ground_mu_k)\n",
    "\n",
    "      if self._terrain is not None:\n",
    "        if self._terrain == \"SLOPES\":\n",
    "          self.add_slopes(pitch=0.2)\n",
    "        elif self._terrain == \"STAIRS\":\n",
    "          self.add_stairs(num_stairs=12, stair_height=0.05, stair_width=0.25)\n",
    "        elif self._terrain == \"GAPS\":\n",
    "          self.add_gaps(num_gaps=5, gap_width=0.1, between_gaps_width=2)\n",
    "        elif self._terrain == \"RANDOM\":\n",
    "          self.add_random_boxes()\n",
    "        else:\n",
    "          print('Terrain',self._terrain,'is not implemented')\n",
    "\n",
    "      elif self._TASK_ENV == \"FLAGRUN\":\n",
    "        self.goal_id = None\n",
    "        if self._test_flagrun:\n",
    "          self._ground_mu_k = ground_mu_k = 0.8\n",
    "          self._pybullet_client.changeDynamics(self.plane, -1, lateralFriction=ground_mu_k)\n",
    "          self._add_noise = False \n",
    "          self._goal_idx = 0\n",
    "          self.goal_x = np.arange(np.pi/4, 11, np.pi/2)\n",
    "          self.goal_y = 0.2 * self.goal_x * np.sin(2*self.goal_x)\n",
    "        self._reset_goal()\n",
    "\n",
    "    else:\n",
    "      self.robot.Reset(reload_urdf=False)\n",
    "\n",
    "    self.setupCPG()\n",
    "    self._env_step_counter = 0\n",
    "    self._sim_step_counter = 0\n",
    "    self._last_base_position = [0, 0, 0]\n",
    "\n",
    "    if self._is_render:\n",
    "      self._pybullet_client.resetDebugVisualizerCamera(self._cam_dist, self._cam_yaw,\n",
    "                                                       self._cam_pitch, [0, 0, 0])\n",
    "\n",
    "    self._settle_robot()\n",
    "    self._last_action = np.zeros(self._action_dim)\n",
    "    if self._is_record_video:\n",
    "      self.recordVideoHelper()\n",
    "    return self._noisy_observation()\n",
    "\n",
    "  def _reset_goal(self):\n",
    "    \"\"\"Reset goal location. \"\"\"\n",
    "    try:\n",
    "      if self.goal_id is not None: \n",
    "        self._pybullet_client.removeBody(self.goal_id)\n",
    "    except:\n",
    "      pass\n",
    "    \n",
    "    if self._test_flagrun:\n",
    "      self._goal_location = np.array([self.goal_x[self._goal_idx], \n",
    "                                      self.goal_y[self._goal_idx]])\n",
    "      self._goal_idx = min(self._goal_idx+1, len(self.goal_x))\n",
    "    else:\n",
    "      self._goal_location = 6 * (np.random.random((2,)) - 0.5) \n",
    "      self._goal_location += self.robot.GetBasePosition()[0:2]\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "        halfExtents=[0.2,0.2,0.2])\n",
    "    orn = self._pybullet_client.getQuaternionFromEuler([0,0,0])\n",
    "    self.goal_id=self._pybullet_client.createMultiBody(\n",
    "                          baseMass=0,\n",
    "                          baseCollisionShapeIndex = sh_colBox,\n",
    "                          basePosition = [self._goal_location[0],self._goal_location[1],0.6],\n",
    "                          baseOrientation=orn)\n",
    "    # print('goal is at ', self._goal_location)\n",
    "\n",
    "  def _settle_robot(self):\n",
    "    \"\"\" Settle robot and add noise to init configuration. \"\"\"\n",
    "    # change to PD control mode to set initial position, then set back..\n",
    "    tmp_save_motor_control_mode_ENV = self._motor_control_mode\n",
    "    tmp_save_motor_control_mode_ROB = self.robot._motor_control_mode\n",
    "    self._motor_control_mode = \"PD\"\n",
    "    self.robot._motor_control_mode = \"PD\"\n",
    "    try:\n",
    "      tmp_save_motor_control_mode_MOT = self.robot._motor_model._motor_control_mode\n",
    "      self.robot._motor_model._motor_control_mode = \"PD\"\n",
    "    except:\n",
    "      pass\n",
    "    init_motor_angles = self._robot_config.INIT_MOTOR_ANGLES + self._robot_config.JOINT_OFFSETS\n",
    "    if self._is_render:\n",
    "      time.sleep(0.2)\n",
    "    for _ in range(1000):\n",
    "      self.robot.ApplyAction(init_motor_angles)\n",
    "      if self._is_render:\n",
    "        time.sleep(0.001)\n",
    "      self._pybullet_client.stepSimulation()\n",
    "    \n",
    "    # set control mode back\n",
    "    self._motor_control_mode = tmp_save_motor_control_mode_ENV\n",
    "    self.robot._motor_control_mode = tmp_save_motor_control_mode_ROB\n",
    "    try:\n",
    "      self.robot._motor_model._motor_control_mode = tmp_save_motor_control_mode_MOT\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  ######################################################################################\n",
    "  # Render, record videos, bookkeping, and misc pybullet helpers.  \n",
    "  ######################################################################################\n",
    "  def startRecordingVideo(self,name):\n",
    "    self.videoLogID = self._pybullet_client.startStateLogging(\n",
    "                            self._pybullet_client.STATE_LOGGING_VIDEO_MP4, \n",
    "                            name)\n",
    "\n",
    "  def stopRecordingVideo(self):\n",
    "    self._pybullet_client.stopStateLogging(self.videoLogID)\n",
    "\n",
    "  def close(self):\n",
    "    if self._is_record_video:\n",
    "      self.stopRecordingVideo()\n",
    "    self._pybullet_client.disconnect()\n",
    "\n",
    "  def recordVideoHelper(self, extra_filename=None):\n",
    "    \"\"\" Helper to record video, if not already, or end and start a new one \"\"\"\n",
    "    # If no ID, this is the first video, so make a directory and start logging\n",
    "    if self.videoLogID == None:\n",
    "      directoryName = VIDEO_LOG_DIRECTORY\n",
    "      assert isinstance(directoryName, str)\n",
    "      os.makedirs(directoryName, exist_ok=True)\n",
    "      self.videoDirectory = directoryName\n",
    "    else:\n",
    "      # stop recording and record a new one\n",
    "      self.stopRecordingVideo()\n",
    "\n",
    "    if extra_filename is not None:\n",
    "      output_video_filename = self.videoDirectory + '/' + datetime.datetime.now().strftime(\"vid-%Y-%m-%d-%H-%M-%S-%f\") +extra_filename+ \".MP4\"\n",
    "    else:\n",
    "      output_video_filename = self.videoDirectory + '/' + datetime.datetime.now().strftime(\"vid-%Y-%m-%d-%H-%M-%S-%f\") + \".MP4\"\n",
    "    logID = self.startRecordingVideo(output_video_filename)\n",
    "    self.videoLogID = logID\n",
    "\n",
    "\n",
    "  def configure(self, args):\n",
    "    self._args = args\n",
    "\n",
    "  def seed(self, seed=None):\n",
    "    self.np_random, seed = seeding.np_random(seed)\n",
    "    return [seed]\n",
    "\n",
    "  def _render_step_helper(self):\n",
    "    \"\"\" Helper to configure the visualizer camera during step(). \"\"\"\n",
    "    # Sleep, otherwise the computation takes less time than real time,\n",
    "    # which will make the visualization like a fast-forward video.\n",
    "    time_spent = time.time() - self._last_frame_time\n",
    "    self._last_frame_time = time.time()\n",
    "    # time_to_sleep = self._action_repeat * self._time_step - time_spent\n",
    "    time_to_sleep = self._time_step - time_spent\n",
    "    if time_to_sleep > 0 and (time_to_sleep < self._time_step):\n",
    "      time.sleep(time_to_sleep)\n",
    "      \n",
    "    base_pos = self.robot.GetBasePosition()\n",
    "    camInfo = self._pybullet_client.getDebugVisualizerCamera()\n",
    "    curTargetPos = camInfo[11]\n",
    "    distance = camInfo[10]\n",
    "    yaw = camInfo[8]\n",
    "    pitch = camInfo[9]\n",
    "    targetPos = [\n",
    "        0.95 * curTargetPos[0] + 0.05 * base_pos[0], 0.95 * curTargetPos[1] + 0.05 * base_pos[1],\n",
    "        curTargetPos[2]\n",
    "    ]\n",
    "    self._pybullet_client.resetDebugVisualizerCamera(distance, yaw, pitch, base_pos)\n",
    "\n",
    "  def _configure_visualizer(self):\n",
    "    \"\"\" Remove all visualizer borders, and zoom in \"\"\"\n",
    "    # default rendering options\n",
    "    self._render_width = 960\n",
    "    self._render_height = 720\n",
    "    self._cam_dist = 1.0 \n",
    "    self._cam_yaw = 0\n",
    "    self._cam_pitch = -30 \n",
    "    # get rid of visualizer things\n",
    "    self._pybullet_client.configureDebugVisualizer(self._pybullet_client.COV_ENABLE_RGB_BUFFER_PREVIEW,0)\n",
    "    self._pybullet_client.configureDebugVisualizer(self._pybullet_client.COV_ENABLE_DEPTH_BUFFER_PREVIEW,0)\n",
    "    self._pybullet_client.configureDebugVisualizer(self._pybullet_client.COV_ENABLE_SEGMENTATION_MARK_PREVIEW,0)\n",
    "    self._pybullet_client.configureDebugVisualizer(self._pybullet_client.COV_ENABLE_GUI,0)\n",
    "\n",
    "  def render(self, mode=\"rgb_array\", close=False):\n",
    "    if mode != \"rgb_array\":\n",
    "      return np.array([])\n",
    "    base_pos = self.robot.GetBasePosition()\n",
    "    view_matrix = self._pybullet_client.computeViewMatrixFromYawPitchRoll(\n",
    "        cameraTargetPosition=base_pos,\n",
    "        distance=self._cam_dist,\n",
    "        yaw=self._cam_yaw,\n",
    "        pitch=self._cam_pitch,\n",
    "        roll=0,\n",
    "        upAxisIndex=2)\n",
    "    proj_matrix = self._pybullet_client.computeProjectionMatrixFOV(fov=60,\n",
    "                                                                   aspect=float(self._render_width) /\n",
    "                                                                   self._render_height,\n",
    "                                                                   nearVal=0.1,\n",
    "                                                                   farVal=100.0)\n",
    "    (_, _, px, _,\n",
    "     _) = self._pybullet_client.getCameraImage(width=self._render_width,\n",
    "                                               height=self._render_height,\n",
    "                                               viewMatrix=view_matrix,\n",
    "                                               projectionMatrix=proj_matrix,\n",
    "                                               renderer=pybullet.ER_BULLET_HARDWARE_OPENGL)\n",
    "    rgb_array = np.array(px)\n",
    "    rgb_array = rgb_array[:, :, :3]\n",
    "    return rgb_array\n",
    "\n",
    "  def addLine(self,lineFromXYZ,lineToXYZ,lifeTime=0,color=[1,0,0]):\n",
    "    \"\"\" Add line between point A and B for duration lifeTime\"\"\"\n",
    "    self._pybullet_client.addUserDebugLine(lineFromXYZ,\n",
    "                                            lineToXYZ,\n",
    "                                            lineColorRGB=color,\n",
    "                                            lifeTime=lifeTime)\n",
    "\n",
    "  def get_sim_time(self):\n",
    "    \"\"\" Get current simulation time. \"\"\"\n",
    "    return self._sim_step_counter * self._time_step\n",
    "\n",
    "  def scale_rand(self,num_rand,low,high):\n",
    "    \"\"\" scale number of rand numbers between low and high \"\"\"\n",
    "    return low + np.random.random(num_rand) * (high - low)\n",
    "\n",
    "  def add_random_boxes(self, num_rand=100, z_height=0.04):\n",
    "    \"\"\"Add random boxes in front of the robot in x [0.5, 20] and y [-3,3] \"\"\"\n",
    "    # x location\n",
    "    x_low, x_upp = 0.5, 20\n",
    "    # y location\n",
    "    y_low, y_upp = -3, 3\n",
    "    # block dimensions\n",
    "    block_x_min, block_x_max = 0.1, 1\n",
    "    block_y_min, block_y_max = 0.1, 1\n",
    "    z_low, z_upp = 0.005, z_height\n",
    "    # block orientations\n",
    "    roll_low, roll_upp = -0.01, 0.01\n",
    "    pitch_low, pitch_upp = -0.01, 0.01 \n",
    "    yaw_low, yaw_upp = -np.pi, np.pi\n",
    "\n",
    "    x = x_low + np.random.random(num_rand) * (x_upp - x_low)\n",
    "    y = y_low + np.random.random(num_rand) * (y_upp - y_low)\n",
    "    z = z_low + np.random.random(num_rand) * (z_upp - z_low)\n",
    "    block_x = self.scale_rand(num_rand,block_x_min,block_x_max)\n",
    "    block_y = self.scale_rand(num_rand,block_y_min,block_y_max)\n",
    "    roll = self.scale_rand(num_rand,roll_low,roll_upp)\n",
    "    pitch = self.scale_rand(num_rand,pitch_low,pitch_upp)\n",
    "    yaw = self.scale_rand(num_rand,yaw_low,yaw_upp)\n",
    "    # loop through\n",
    "    for i in range(num_rand):\n",
    "      sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "          halfExtents=[block_x[i]/2,block_y[i]/2,z[i]/2])\n",
    "      orn = self._pybullet_client.getQuaternionFromEuler([roll[i],pitch[i],yaw[i]])\n",
    "      block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                            basePosition = [x[i],y[i],z[i]/2],baseOrientation=orn)\n",
    "      # set friction coeff\n",
    "      self._pybullet_client.changeDynamics(block2, -1, lateralFriction=self._ground_mu_k)\n",
    "\n",
    "    # add walls \n",
    "    orn = self._pybullet_client.getQuaternionFromEuler([0,0,0])\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "        halfExtents=[x_upp/2,0.5,0.5])\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                          basePosition = [x_upp/2,y_low,0.5],baseOrientation=orn)\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                          basePosition = [x_upp/2,-y_low,0.5],baseOrientation=orn)\n",
    "\n",
    "\n",
    "  def add_gaps(self, num_gaps=5, gap_width=0.1, between_gaps_width=2):\n",
    "    \"\"\"Add N gaps\n",
    "      -each gap is gap_width wide\n",
    "      -platforms between gaps are between_gaps_width wide\"\"\"\n",
    "    orn = self._pybullet_client.getQuaternionFromEuler([0,0,0])\n",
    "    # start platform\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "            halfExtents=[2,1,0.5])\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                              basePosition = [0,0,0.5],baseOrientation=orn)\n",
    "    # set friction coeff to 1\n",
    "    self._pybullet_client.changeDynamics(block2, -1, lateralFriction=self._ground_mu_k)\n",
    "\n",
    "    first_gap = 2\n",
    "    block_0 = first_gap + gap_width + between_gaps_width / 2\n",
    "    # keep track of gaps (possibly for RL observation space!)\n",
    "    self._gap_centers = np.zeros(num_gaps) \n",
    "\n",
    "    # loop through\n",
    "    for i in range(num_gaps):\n",
    "      self._gap_centers[i] = first_gap + gap_width / 2 + i*between_gaps_width\n",
    "      block_x = block_0 + i * (gap_width + between_gaps_width)\n",
    "      sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "          halfExtents=[between_gaps_width / 2, 1, 0.5])\n",
    "      \n",
    "      block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                            basePosition = [block_x,0,0.5],baseOrientation=orn)\n",
    "      # set friction coeff to 1\n",
    "      self._pybullet_client.changeDynamics(block2, -1, lateralFriction=self._ground_mu_k)\n",
    "    # print(\"gaps are centered at\", self._gap_centers)\n",
    "\n",
    "    # end platform \n",
    "    end_platform_size = 2\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "            halfExtents=[end_platform_size,1,0.5])\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                              basePosition = [block_x+between_gaps_width/2+end_platform_size/2,0,0.5],baseOrientation=orn)\n",
    "    # set friction coeff to 1\n",
    "    self._pybullet_client.changeDynamics(block2, -1, lateralFriction=self._ground_mu_k)\n",
    "  \n",
    "  def add_stairs(self, num_stairs=12, stair_height=0.05, stair_width=0.25):\n",
    "    \"\"\"Add N stairs, with stair_height and stair_width. long so can't get around \"\"\"\n",
    "    x_upp = 20\n",
    "    y_low = -3\n",
    "    y = 6\n",
    "    curr_z = 0 \n",
    "    block_x = stair_width * np.ones(num_stairs)\n",
    "    curr_x = 1\n",
    "    # loop through\n",
    "    for i in range(num_stairs):\n",
    "      if i < num_stairs / 2:\n",
    "        curr_z += stair_height\n",
    "      else:\n",
    "        curr_z -= stair_height\n",
    "      if curr_z > 0:\n",
    "        sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "            halfExtents=[block_x[i]/2,y/2,curr_z/2])\n",
    "        orn = self._pybullet_client.getQuaternionFromEuler([0,0,0])\n",
    "        block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                              basePosition = [curr_x,0,curr_z/2],baseOrientation=orn)\n",
    "        # set friction coeff to 1\n",
    "        self._pybullet_client.changeDynamics(block2, -1, lateralFriction=self._ground_mu_k)\n",
    "\n",
    "      curr_x += block_x[i]\n",
    "\n",
    "    # add walls \n",
    "    orn = self._pybullet_client.getQuaternionFromEuler([0,0,0])\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "        halfExtents=[x_upp/2,0.5,0.5])\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                          basePosition = [x_upp/2,y_low,0.5],baseOrientation=orn)\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                          basePosition = [x_upp/2,-y_low,0.5],baseOrientation=orn)\n",
    "\n",
    "  def add_slopes(self, pitch=0.2):\n",
    "    \"\"\"Add slopes with platform in center.\"\"\"\n",
    "    y = 6\n",
    "    slope_len = 2\n",
    "    box_width = 1\n",
    "    slope_height = 0.01\n",
    "\n",
    "    # add first slope UP\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "        halfExtents=[slope_len/2,y/2,slope_height])\n",
    "    orn = self._pybullet_client.getQuaternionFromEuler([0,-pitch,0])\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex=sh_colBox,\n",
    "        basePosition = [1+slope_len/2,0,slope_len/2*np.sin(pitch) - slope_height*np.cos(pitch) ],baseOrientation=orn)\n",
    "    self._pybullet_client.changeDynamics(block2, -1, lateralFriction=self._ground_mu_k)\n",
    "\n",
    "    # add middle box\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "        halfExtents=[box_width/2,y/2,slope_len/2*np.sin(pitch)])\n",
    "    orn = self._pybullet_client.getQuaternionFromEuler([0,0,0])\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex=sh_colBox,\n",
    "        basePosition = [1+slope_len*np.cos(pitch)+box_width/2,0,slope_len/2*np.sin(pitch)  ],baseOrientation=orn) # + slope_height/2*np.cos(pitch)\n",
    "    self._pybullet_client.changeDynamics(block2, -1, lateralFriction=self._ground_mu_k)\n",
    "\n",
    "    # add descending box\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "        halfExtents=[slope_len/2,y/2,slope_height])\n",
    "    orn = self._pybullet_client.getQuaternionFromEuler([0,pitch,0])\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex=sh_colBox,\n",
    "        basePosition = [1+slope_len*np.cos(pitch)+box_width + slope_len/2 + 2*slope_height*np.sin(-pitch),0,slope_len/2*np.sin(pitch) - slope_height*np.cos(pitch) ],baseOrientation=orn) # + slope_height/2*np.cos(pitch)\n",
    "    self._pybullet_client.changeDynamics(block2, -1, lateralFriction=self._ground_mu_k)\n",
    "\n",
    "    self._add_walls()\n",
    "\n",
    "  def _add_walls(self,x_upp=20,y_low=-3):\n",
    "    # add walls \n",
    "    orn = self._pybullet_client.getQuaternionFromEuler([0,0,0])\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX,\n",
    "        halfExtents=[x_upp/2,0.25,0.5])\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                          basePosition = [x_upp/2,y_low,0.5],baseOrientation=orn)\n",
    "    block2=self._pybullet_client.createMultiBody(baseMass=0,baseCollisionShapeIndex = sh_colBox,\n",
    "                          basePosition = [x_upp/2,-y_low,0.5],baseOrientation=orn)\n",
    "\n",
    "  def _add_base_mass_offset(self, spec_mass=None, spec_location=None):\n",
    "    \"\"\"Attach mass to robot base.\"\"\"\n",
    "    quad_base = np.array(self.robot.GetBasePosition())\n",
    "    quad_ID = self.robot.quadruped\n",
    "\n",
    "    offset_low = np.array([-0.15, -0.05, -0.05])\n",
    "    offset_upp = np.array([ 0.15,  0.05,  0.05])\n",
    "    if spec_location is None:\n",
    "      block_pos_delta_base_frame = self.scale_rand(3,offset_low,offset_upp)\n",
    "    else:\n",
    "      block_pos_delta_base_frame = np.array(spec_location)\n",
    "    if spec_mass is None:\n",
    "      base_mass = 8*np.random.random()\n",
    "    else:\n",
    "      base_mass = spec_mass\n",
    "    if self._is_render:\n",
    "      print('=========================== Random Mass:')\n",
    "      print('Mass:', base_mass, 'location:', block_pos_delta_base_frame)\n",
    "      # if rendering, also want to set the halfExtents accordingly \n",
    "      # 1 kg water is 0.001 cubic meters \n",
    "      boxSizeHalf = [(base_mass*0.001)**(1/3) / 2]*3\n",
    "      translationalOffset = [0,0,0.1]\n",
    "    else:\n",
    "      boxSizeHalf = [0.05]*3\n",
    "      translationalOffset = [0]*3\n",
    "\n",
    "    sh_colBox = self._pybullet_client.createCollisionShape(self._pybullet_client.GEOM_BOX, \n",
    "                      halfExtents=boxSizeHalf, collisionFramePosition=translationalOffset)\n",
    "    base_block_ID=self._pybullet_client.createMultiBody(baseMass=base_mass,\n",
    "                                    baseCollisionShapeIndex = sh_colBox,\n",
    "                                    basePosition = quad_base + block_pos_delta_base_frame,\n",
    "                                    baseOrientation=[0,0,0,1])\n",
    "\n",
    "    cid = self._pybullet_client.createConstraint(quad_ID, -1, base_block_ID, -1, \n",
    "          self._pybullet_client.JOINT_FIXED, [0, 0, 0], [0, 0, 0], -block_pos_delta_base_frame)\n",
    "    # disable self collision between box and each link\n",
    "    for i in range(-1,self._pybullet_client.getNumJoints(quad_ID)):\n",
    "      self._pybullet_client.setCollisionFilterPair(quad_ID,base_block_ID, i,-1, 0)\n",
    "\n",
    "\n",
    "def test_env():\n",
    "  env = QuadrupedGymEnv(render=True, \n",
    "                        on_rack=True,\n",
    "                        motor_control_mode='PD',\n",
    "                        action_repeat=100,\n",
    "                        )\n",
    "\n",
    "  obs = env.reset()\n",
    "  print('obs len', len(obs))\n",
    "  action_dim = env._action_dim\n",
    "  action_low = -np.ones(action_dim)\n",
    "  print('act len', action_dim)\n",
    "  action = action_low.copy()\n",
    "  while True:\n",
    "    action = 2*np.random.rand(action_dim)-1\n",
    "    obs, reward, done, info = env.step(action)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  # test out some functionalities\n",
    "  test_env()\n",
    "  sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a49370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
